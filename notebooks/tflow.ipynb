{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Neural Networks\n",
    "\n",
    "![Artificial Neurons](artificial_neuron.png \"Artificial Neuron\")\n",
    "\n",
    "## What is machine learning?\n",
    "\n",
    "* Subfield of artificial intelligence that deals with pattern recognition\n",
    "* Statistical in nature, as opposed to traditional artificial intelligence\n",
    "* Examples:\n",
    "  * Handwriting recognition:\n",
    "  ![Sample of MNIST](mnist.png \"Handwriting recognition\")\n",
    "  * Facial recognition:\n",
    "  ![Picture of G-Wash](gwash.jpg \"Facial recognition\")\n",
    "  * Speech recognition:\n",
    "  ![Speech signal](speech.png \"Speech recognition\")\n",
    "  * Knowledge discovery:\n",
    "  ![Google Neural style](neural_style.png \"Knowledge discovery\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine learning problem specification\n",
    "\n",
    "**Supervised learning**\n",
    "* Given pairs of `(X = input_data, y = observed_result)`, estimate a function $f(X) = y$\n",
    "* Pairs of data referred to as training data points\n",
    "\n",
    "**Unsupervised learning**\n",
    "* Only given inputs, no labeled outputs\n",
    "* Objective is to find patterns or clusters in data\n",
    "\n",
    "We are focusing on supervised learning in this talk. A formalization of supervised learning is:\n",
    "\n",
    "Define an input matrix $X$ and an output matrix $Y$ as\n",
    "\n",
    "$$X = \\begin{bmatrix}\n",
    " x_{11}  & x_{12} & \\cdots & x_{1m} \\\\ \n",
    " x_{21} & x_{22}  & \\cdots & x_{2m} \\\\\n",
    " \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    " x_{n1} & x_{n2} & \\cdots & x_{nm} \n",
    "\\end{bmatrix},\\  Y = \\begin{bmatrix}\n",
    " y_{11}  & y_{12} & \\cdots & y_{1k} \\\\ \n",
    " y_{21} & y_{22}  & \\cdots & y_{2k} \\\\\n",
    " \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    " y_{n1} & y_{n2} & \\cdots & y_{nk} \n",
    "\\end{bmatrix}$$\n",
    "\n",
    "The goal of most machine learning algorithms is to estimate some function $f : X \\rightarrow Y$, where $X$ is an input matrix with $n$ samples and $m$ dimensions, and $Y$ is an output matrix with $n$ samples and $k$ dimensions. In practice, $Y$ often has one dimension. Below are some examples:\n",
    "  * Predicting market value of house\n",
    "    * $X$ - information about houses on the market (square feet, location, sales of neighboring houses)\n",
    "    * $Y$ - the prices these houses sold for\n",
    "  * Chess AI\n",
    "    * $X$ - information about the state of the board for particular moves\n",
    "    * $Y$ - the observed moves from these states\n",
    "  * Handwriting recognition\n",
    "    * $X$ - pixel values of images containing a handwritten character\n",
    "    * $Y$ - the characters which the images represent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "\n",
    "![NN Architecture](nn_arch.svg \"Neural Net Architecture\")\n",
    "\n",
    "* Neurons are **activated** at certain level, which is then **propagated** forward through the various layers\n",
    "* The strength of activation are controlled by the **weights** of the connections (denoted by arrows)\n",
    "* A unit's activation is a function of the previous layer's activations, the connection strengths from the previous layer to that particular unit, and some **activation function**\n",
    "\n",
    "### Neuron computation\n",
    "\n",
    "Assume that the previous layer has $D$ units, the $i$th unit of which has an activation of $x_i$. The activation of a unit $z_j$ in the next layer has an activation of the form:\n",
    "\n",
    "$$z_j = f(\\sum_{i=1}^{D} x_{i}w_{ij})$$\n",
    "\n",
    "where $w_{ij}$ is the connection weight from unit $x_i$ to $z_j$. In English: a unit's activation is the weighted sum of the previous layer's activation, passed through some function $f(\\cdot)$.\n",
    "\n",
    "**What's this function $f(\\cdot)$?**\n",
    "\n",
    "This is the activation function, and it allows non-linear transformations at each layer. Some common activation functions:\n",
    "\n",
    "**Linear**\n",
    "<img src=\"linear.png\",width=500,height=500>\n",
    "\n",
    "**Sigmoid**\n",
    "<img src=\"sigmoid.png\",width=500,height=500>\n",
    "\n",
    "**Tanh**\n",
    "<img src=\"tanh.png\",width=500,height=500>\n",
    "\n",
    "**Rectified Linear Unit**\n",
    "<img src=\"relu.png\",width=500,height=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training neural networks\n",
    "\n",
    "* Define loss function (eg. $L(\\hat{y}, y) = \\frac{1}{N}\\sum_{i=1}^{N} (\\hat{y_i} - y_i)^2$)\n",
    "* Train networks using various **gradient descent** approaches\n",
    "* Basic idea: update weights according to their contribution to the error so that you \"descend\" down the error curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isachsquintana/Documents/pymy/twenty_newsgroups/v36/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: 1797x64 matrix, y: 1797x10 matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112d3d7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read in the MNIST dataset from sci-kit learn\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn import cross_validation\n",
    "data = datasets.load_digits()\n",
    "X, y = data['data'], pd.get_dummies(data['target'])\n",
    "print('X: %dx%d matrix, y: %dx%d matrix' % (X.shape + y.shape))\n",
    "\n",
    "# Plot some examples\n",
    "for i in range(1,13):\n",
    "    plt.subplot(2, 6, i)\n",
    "    plt.imshow(data.images[i], cmap=plt.cm.gray, interpolation='nearest')\n",
    "\n",
    "# Last but not least, split the data into a training and test set\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.33, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tensorflow package\n",
    "import tensorflow as tf\n",
    "\n",
    "# Create a session object\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/isachsquintana/Documents/pymy/twenty_newsgroups/v36/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "# Define some placeholder variables\n",
    "x_ = tf.placeholder(tf.float32, shape=[None, 64])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "# Define the network computation\n",
    "W = tf.Variable(tf.zeros([64, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "yhat = tf.nn.softmax(tf.matmul(x_, W) + b)\n",
    "\n",
    "# Define our loss function\n",
    "mse_loss = tf.reduce_mean(tf.square(yhat - y_))\n",
    "\n",
    "# Compute accuracy computation\n",
    "correct_prediction = tf.equal(tf.argmax(yhat,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Set up the training methods\n",
    "train_step = tf.train.AdamOptimizer(0.1).minimize(mse_loss)\n",
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step: 0, Loss: 0.074, Accuracy: 56.229%\n",
      "Train step: 100, Loss: 0.042, Accuracy: 77.778%\n",
      "Train step: 200, Loss: 0.040, Accuracy: 79.293%\n",
      "Train step: 300, Loss: 0.038, Accuracy: 79.293%\n",
      "Train step: 400, Loss: 0.043, Accuracy: 77.609%\n",
      "Train step: 500, Loss: 0.041, Accuracy: 78.620%\n",
      "Train step: 600, Loss: 0.040, Accuracy: 79.125%\n",
      "Train step: 700, Loss: 0.042, Accuracy: 78.451%\n",
      "Train step: 800, Loss: 0.040, Accuracy: 79.125%\n",
      "Train step: 900, Loss: 0.044, Accuracy: 77.273%\n",
      "Train step: 1000, Loss: 0.043, Accuracy: 77.441%\n",
      "Train step: 1100, Loss: 0.042, Accuracy: 78.451%\n",
      "Train step: 1200, Loss: 0.042, Accuracy: 78.620%\n",
      "Train step: 1300, Loss: 0.041, Accuracy: 78.956%\n",
      "Train step: 1400, Loss: 0.041, Accuracy: 78.620%\n",
      "Train step: 1500, Loss: 0.043, Accuracy: 78.283%\n"
     ]
    }
   ],
   "source": [
    "# Train the model!\n",
    "n_iters = 1500\n",
    "for i in range(n_iters+1):\n",
    "    # Run through an iteration of the training process\n",
    "    train_step.run(feed_dict={x_: X_train, y_: y_train})\n",
    "    \n",
    "    # Compute the accuracy and loss\n",
    "    if i % 100 == 0:\n",
    "        current_loss = mse_loss.eval(feed_dict={x_: X_test, y_: y_test})\n",
    "        current_acc  = accuracy.eval(feed_dict={x_: X_test, y_: y_test})\n",
    "        print('Train step: %d, Loss: %.3f, Accuracy: %.3f%%' % (i, current_loss, current_acc * 100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are creating two weight matrices, one that contains the\n",
    "# weights connecting the input units to the hidden units, and one\n",
    "# connecting the hidden units to the output units\n",
    "n_inputs = 64\n",
    "n_hidden = 64\n",
    "n_outputs = 10\n",
    "W_input_to_hidden = tf.Variable(tf.truncated_normal([n_inputs, n_hidden], stddev=0.1))\n",
    "W_hidden_to_output = tf.Variable(tf.truncated_normal([n_hidden, n_outputs], stddev=0.1))\n",
    "b_hidden = tf.Variable(tf.constant(0.1, shape=[n_hidden]))\n",
    "b_output = tf.Variable(tf.constant(0.1, shape=[n_outputs]))\n",
    "\n",
    "# We now redefine the neural computation. I'm showing it here in\n",
    "# two steps: one for each layer in the network\n",
    "hidden_activation = tf.nn.sigmoid(tf.matmul(x_, W_input_to_hidden) + b_hidden)\n",
    "yhat = tf.nn.softmax(tf.matmul(hidden_activation, W_hidden_to_output) + b_output)\n",
    "\n",
    "############################\n",
    "# The rest is the same...\n",
    "mse_loss = tf.reduce_mean(tf.square(yhat - y_))\n",
    "correct_prediction = tf.equal(tf.argmax(yhat,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "train_step = tf.train.AdagradOptimizer(0.1).minimize(mse_loss)\n",
    "sess.run(tf.initialize_all_variables())\n",
    "n_iters = 1500\n",
    "for i in range(n_iters+1):\n",
    "    train_step.run(feed_dict={x_: X_train, y_: y_train})\n",
    "    if i % 100 == 0:\n",
    "        current_loss = mse_loss.eval(feed_dict={x_: X_test, y_: y_test})\n",
    "        current_acc  = accuracy.eval(feed_dict={x_: X_test, y_: y_test})\n",
    "        print 'Train step: %d, Loss: %.3f, Accuracy: %.3f%%' % (i, current_loss, current_acc * 100.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual intuition of hidden layers\n",
    "\n",
    "Using `sci-kit learn`'s `datasets` module, I create a dataset containing two clusters of points, one that is an outer circle and one that is an inner circle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a circular dataset\n",
    "X_circles, y_circles = datasets.make_circles(n_samples=1000, noise=0.1, random_state=1234, factor=0.5)\n",
    "plt.scatter(X_circles[:,0], X_circles[:,1], c=y_circles, alpha=0.5, s=50)\n",
    "ys, y_circles = y_circles, pd.get_dummies(y_circles)\n",
    "\n",
    "# Separate out the data into training and test sets\n",
    "X_circles_train, X_circles_test, y_circles_train, y_circles_test = cross_validation.train_test_split(\n",
    "            X_circles, y_circles, test_size=0.33, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the network with the given number of hidden layers\n",
    "def create_network(X, y, layers=None):\n",
    "    n_in, n_out = X.shape[1], y.shape[1]\n",
    "    \n",
    "    # Make sure we get a list in\n",
    "    layers = layers or list()\n",
    "    layers = [n_in] + layers + [n_out]\n",
    "    \n",
    "    # Initialize input/output\n",
    "    x  = tf.placeholder(tf.float32, shape=[None, n_in])\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, n_out])\n",
    "    yhat = x\n",
    "    \n",
    "    # Create the hidden layers\n",
    "    for i in range(len(layers)-1):\n",
    "        W = tf.Variable(tf.random_uniform([layers[i], layers[i+1]], minval=-1, maxval=1, seed=1234))\n",
    "        b = tf.Variable(tf.random_uniform([layers[i+1]], minval=-1, maxval=1, seed=1234))\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        yhat = tf.sigmoid(tf.matmul(yhat, W) + b)\n",
    "    \n",
    "    # Do softmax at the output layer\n",
    "    yhat = tf.nn.softmax(yhat)\n",
    "    \n",
    "    return yhat, x, y_\n",
    "\n",
    "# Trains the network and optionally plots the results\n",
    "def train_network(X, y, layers=None, n_iters=100, plot_step=10):\n",
    "    yhat, x, y_ = create_network(X, y, layers=layers)\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    \n",
    "    # Define the loss function\n",
    "    cross_entropy = tf.reduce_sum(-tf.reduce_sum(y_ * tf.log(yhat)))\n",
    "    train_step = tf.train.AdamOptimizer(0.05).minimize(cross_entropy)\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    \n",
    "    # Define accuracy\n",
    "    correct_prediction = tf.equal(tf.argmax(yhat,1), tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    for i in range(n_iters+1):\n",
    "        train_step.run(feed_dict={x: X, y_: y})\n",
    "        if plot_step is not None and i % plot_step == 0:\n",
    "            # Compute accuracy and loss\n",
    "            loss = cross_entropy.eval(feed_dict={x: X, y_: y})\n",
    "            acc = accuracy.eval(feed_dict={x: X, y_: y})\n",
    "            preds = tf.argmax(yhat,1).eval(feed_dict={x: X, y_: y})\n",
    "            \n",
    "            # Plot the results all interactive-like\n",
    "            plt.clf()\n",
    "            plt.scatter(X[:,0], X[:,1], c=np.round(preds), alpha=0.5, s=50)\n",
    "            plt.title('Iter #%d' % i)\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With no hidden layers...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_network(X_circles, y_circles, layers=[], n_iters=400, plot_step=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with hidden layers....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_network(X_circles, y_circles, layers=[10], n_iters=100, plot_step=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other features of TensorFlow\n",
    "\n",
    "* GPU computing: [https://www.tensorflow.org/versions/r0.9/how_tos/using_gpu/index.html](https://www.tensorflow.org/versions/r0.9/how_tos/using_gpu/index.html)\n",
    "* Cluster computing: [https://www.tensorflow.org/versions/r0.9/how_tos/distributed/index.html](https://www.tensorflow.org/versions/r0.9/how_tos/distributed/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This notebook: [https://github.com/mcraig2/pygotham-talk/blob/master/tflow.ipynb](https://github.com/mcraig2/pygotham-talk/blob/master/tflow.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
